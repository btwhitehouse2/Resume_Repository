{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww20520\viewh18640\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 //can have data loaded onto master node in order for hive to work we have to load data onto\
//the worker nodes with a put statement\
\
hdfs dfs -put Filtered_Cook_County_Foreclosure_2013_through_March_27_2015.csv /bwhitehouse/project\
\
//we can check to see if this worked with the following\
\
hdfs dfs -ls /bwhitehouse/project/\
\
//now need to creat the correct corresponding tables\
\
/log into hive do the following\
create external table mortgage_csv(\
  Pin string,\
  DocNumber BIGINT, \
  DocType string, \
  DateRecord string,\
  DateExecute string,\
  Amount double,\
  Street string,\
  City string,\
  State string,\
  ZipCode string,\
  Location string)\
  row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\
\
WITH SERDEPROPERTIES (\
   "separatorChar" = "\\,",\
   "quoteChar"     = "\\""\
)\
STORED AS TEXTFILE\
LOCATION "/bwhitehouse/final"\
TBLPROPERTIES ("skip.header.line.count"="1");\
\
\
-- Run a test query to make sure the above worked correctly\
select * from mortgage_csv limit 10;\
\
\
-- Create an ORC table for forclosure data (Note "stored as ORC" at the end)\
create table mortgage(\
  Pin string,\
  DocNumber BIGINT, \
  DocType string, \
  DateRecord string,\
  DateExecute string,\
  Amount double,\
  Street string,\
  City string,\
  State string,\
  ZipCode string,\
  Location string)\
  stored as orc;\
\
-- Copy the CSV table to the ORC table\
insert overwrite table mortgage select * from mortgage_csv\
where amount is not null and location is not null;\
\
-- Run a test query to make sure the above worked correctly\
select * from mortgage limit 5;}